import os
os.environ["CUDA_VISIBLE_DEVICES"] = '0'
import sys
sys.path.append('..')
from utils.dataset import getDataset
from models.tracker_eval import *
from torch.utils.data import DataLoader
import numpy as np
import torch
import cv2
import threading
import time
sys.path.append("/usr/lib/python3/dist-packages/")

from metavision_core.event_io import EventsIterator
from metavision_core.event_io.raw_reader import initiate_device
from metavision_sdk_core import PeriodicFrameGenerationAlgorithm, ColorPalette
from metavision_sdk_ui import EventLoop, BaseWindow, MTWindow, UIKeyEvent

def setup_camera(serial, cam_mode):
    # æ‰“å°ç›¸æœºä¿¡æ¯
    print(f"\nğŸš€ Starting camera {serial} in mode: {cam_mode.upper()}")
    # è¿æ¥è®¾å¤‡
    try:
        device = initiate_device(path=serial)
    except Exception as e:
        print(f"âŒ Could not initiate device {serial}: {e}")
        return
    # æ‰“å°è®¾å¤‡ä¿¡æ¯
    try:
        print(f"âœ… Connected to device with serial: {device.get_serial()}")
    except:
        print("âš ï¸  Warning: Unable to get serial number.")

    sync_iface = device.get_i_camera_synchronization()
    if not sync_iface:
        print("âŒ Device does not support synchronization interface.")
        return
    # è®¾ç½®ä¸º master / slave æ¨¡å¼
    try:
        if cam_mode == "master":
            sync_iface.set_mode_master()
            print("âœ… Set to MASTER mode.")
        else:
            sync_iface.set_mode_slave()
            print("âœ… Set to SLAVE mode.")
    except Exception as e:
        print(f"âŒ Failed to set {cam_mode} mode: {e}")
        return

    # åˆ›å»ºæ˜¾ç¤ºçª—å£ï¼Œæ˜¾ç¤ºäº‹ä»¶å›¾åƒ
    mv_iterator = EventsIterator.from_device(device=device)
    height, width = mv_iterator.get_size()
    title = f"Metavision - {cam_mode.upper()} ({serial})"
    # ä»è®¾å¤‡è¯»å–äº‹ä»¶æµã€‚
    with MTWindow(title=title, width=width, height=height,
                  mode=BaseWindow.RenderMode.BGR) as window:
        # è®¾ç½®é”®ç›˜å›è°ƒå‡½æ•°
        def keyboard_cb(key, scancode, action, mods):
            if key in [UIKeyEvent.KEY_ESCAPE, UIKeyEvent.KEY_Q]:
                window.set_close_flag()
        window.set_keyboard_callback(keyboard_cb)
        # åˆ›å»ºäº‹ä»¶å¸§ç”Ÿæˆå™¨
        frame_gen = PeriodicFrameGenerationAlgorithm(width, height, fps=300, palette=ColorPalette.CoolWarm)
        # è®¾ç½®å¸§è¾“å‡ºå›è°ƒå‡½æ•°
        def on_frame_cb(ts, frame):
            window.show_async(frame)

        frame_gen.set_output_callback(on_frame_cb)

        # äº‹ä»¶å¤„ç†ä¸»å¾ªç¯
        for evs in mv_iterator:
            EventLoop.poll_and_dispatch()
            # æŠŠå½“å‰æ—¶é—´æ®µçš„äº‹ä»¶ä¸¢è¿› frame_gen èšåˆæˆå¸§ã€‚
            frame_gen.process_events(evs)
            if window.should_close():
                break


def draw_tracking(img, points, color=(0, 255, 0)):
    """ åœ¨å›¾åƒä¸Šç”»å‡ºç‚¹è½¨è¿¹ """
    for pt in points:
        pt_int = tuple(pt.astype(int))
        cv2.circle(img, pt_int, 2, color, -1)
    return img

if __name__ == '__main__':
    ckpt_path = '/home/wangzhe/ICRA2025/E-3DTrack/ckpt.pth'
    data_folder = '/home/wangzhe/ICRA2025/E-3DTrack/E-3DTrack'

    # åŠ è½½ TrackerNetEval æ¨¡å‹ï¼ˆæŒ‡å®šä½¿ç”¨ HGNNï¼Œé«˜ç»´ç‰¹å¾ç»´åº¦384ï¼‰
    model = TrackerNetEval(feature_dim=384, hgnn=True)
    model_info = torch.load(ckpt_path)
    model.load_state_dict(model_info["state_dict"])
    model = model.cuda()
    # åŠ è½½æµ‹è¯•æ•°æ®é›†
    testDataset = getDataset(data_folder=data_folder, train=False)

    # âœ… åˆå§‹åŒ–å¯è°ƒèŠ‚å¤§å°çš„çª—å£
    window_name = 'Tracking - Left View'
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    cv2.resizeWindow(window_name, 800, 600)

    # âœ… é€å¸§å¤„ç†æµ‹è¯•æ•°æ®é›†
    with torch.no_grad():
        # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
        model.eval()
        # éå†æ¯ä¸ªæµ‹è¯•åºåˆ—
        for n, td in enumerate(testDataset):
            # è¯»å–æ•°æ®
            DL = DataLoader(td, 1)
            # é‡ç½®æ¨¡å‹çŠ¶æ€
            model.reset()
            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
            opFolder = os.path.join('./output', td.sequence_name)
            # ç¡®ä¿è¾“å‡ºæ–‡ä»¶å¤¹å­˜åœ¨
            os.makedirs(opFolder, exist_ok=True)
            # é€å¸§å¤„ç†
            for i, (ts, data, gt) in enumerate(DL):
                # å°†æ•°æ®ç§»åŠ¨åˆ° GPU
                for k, v in data.items():
                    data[k] = v.cuda()
                # å°† GT æ•°æ®ç§»åŠ¨åˆ° GPU
                for k, v in gt.items():
                    gt[k] = v.cuda()

                # è¯»å–æ•°æ®
                current_pos_l = data['u_centers_l'] # åˆå§‹è·Ÿè¸ªç‚¹
                ref_patch = data['ref_img']         # å‚è€ƒå›¾åƒ patch
                pred = None
                pos_l = []                          # ä¿å­˜2Dä½ç½®
                disp = []                           # ä¿å­˜è§†å·®
                pos_3d = []                         # ä¿å­˜3Dä½ç½®
                tracked_2d = []                     # ä¿å­˜è½¨è¿¹
                threads = []

                # é…ç½®äº‹ä»¶ç›¸æœº
                lc = threading.Thread(target=setup_camera, args=("00051195", "slave"))
                lc.start()
                threads.append(lc)
                time.sleep(1)  # å°å»¶è¿Ÿä»¥é˜²åˆå§‹åŒ–å†²çª
                rc = threading.Thread(target=setup_camera, args=("00051197", "master"))
                rc.start()
                threads.append(rc)

                for unroll in range(data['ev_frame_left'].shape[1]):
                    # è¯»å–å½“å‰å¸§çš„äº‹ä»¶æ•°æ®
                    ev_frame_l = threading.Thread(target=setup_camera, args=("00051195", "slave"))
                    ev_frame_l.start()
                    threads.append(ev_frame_l)
                    time.sleep(1)  # å°å»¶è¿Ÿä»¥é˜²åˆå§‹åŒ–å†²çª
                    ev_frame_r  = threading.Thread(target=setup_camera, args=("00051197", "master"))
                    ev_frame_r.start()
                    threads.append(ev_frame_r)
                    # ev_frame_l = data['ev_frame_left'][:, unroll]   # å·¦äº‹ä»¶ç›¸æœº
                    # ev_frame_r = data['ev_frame_right'][:, unroll]  # å³äº‹ä»¶ç›¸æœº
                    # è¯»å–å½“å‰å¸§çš„ GT æ•°æ®
                    flow_l_pred, disp_pred, pred = model(
                        ev_frame_l, ev_frame_r, ref_patch, current_pos_l, None, pred=pred
                    )
                    current_pos_l += flow_l_pred.detach()           # æ›´æ–°å½“å‰è·Ÿè¸ªç‚¹
                    pos = td.reprojectImageTo3D_ph(disp_pred[0].cpu(), current_pos_l[0].cpu())  # 3Dä½ç½®
                    # è®¡ç®—å½“å‰è·Ÿè¸ªç‚¹çš„3Dä½ç½®
                    disp.append(disp_pred)
                    # è®¡ç®—å½“å‰è·Ÿè¸ªç‚¹çš„è§†å·®
                    pos_l.append(current_pos_l.clone())
                    # ä¿å­˜å½“å‰è·Ÿè¸ªç‚¹çš„2Dä½ç½®
                    pos_3d.append(pos)

                    # âœ… ç”¨äº‹ä»¶å¸§å¯è§†åŒ–ï¼ˆå¤šé€šé“å–å¹³å‡ï¼‰
                    ev_img = ev_frame_l[0].detach().cpu()  # shape: [10, H, W]
                    # å°†äº‹ä»¶å¸§è½¬æ¢ä¸ºå›¾åƒ
                    if ev_img.ndim == 3 and ev_img.shape[0] == 10:
                        ev_img_vis = ev_img.mean(dim=0).numpy() * 255           # shape: [H, W]
                        img = np.stack([ev_img_vis]*3, axis=-1).astype(np.uint8)# shape: [H, W, 3]
                    else:
                        raise ValueError(f"Unsupported ev_frame_l shape: {ev_img.shape}")
                    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)                 # OpenCV BGRæ ¼å¼

                    # âœ… ç»˜åˆ¶è½¨è¿¹
                    tracked_2d.append(current_pos_l[0].cpu().numpy())
                    # ç»˜åˆ¶å½“å‰è·Ÿè¸ªç‚¹
                    for p in tracked_2d:
                        # ç»˜åˆ¶è½¨è¿¹
                        img = draw_tracking(img, p)
                    # ç»˜åˆ¶å½“å‰è·Ÿè¸ªç‚¹
                    img = draw_tracking(img, current_pos_l[0].cpu().numpy(), color=(0, 0, 255))
                    # ç»˜åˆ¶å‚è€ƒå›¾åƒ
                    cv2.imshow(window_name, img)
                    key = cv2.waitKey(30)
                    if key == 27:  # ESC é€€å‡º
                        break

                # é€å¸§å¤„ç†
                # for unroll in range(data['ev_frame_left'].shape[1]):
                #     # è¯»å–å½“å‰å¸§çš„äº‹ä»¶æ•°æ®
                #     ev_frame_l = data['ev_frame_left'][:, unroll]   # å·¦äº‹ä»¶ç›¸æœº
                #     ev_frame_r = data['ev_frame_right'][:, unroll]  # å³äº‹ä»¶ç›¸æœº
                #     # è¯»å–å½“å‰å¸§çš„ GT æ•°æ®
                #     flow_l_pred, disp_pred, pred = model(
                #         ev_frame_l, ev_frame_r, ref_patch, current_pos_l, None, pred=pred
                #     )
                #     current_pos_l += flow_l_pred.detach()           # æ›´æ–°å½“å‰è·Ÿè¸ªç‚¹
                #     pos = td.reprojectImageTo3D_ph(disp_pred[0].cpu(), current_pos_l[0].cpu())  # 3Dä½ç½®
                #     # è®¡ç®—å½“å‰è·Ÿè¸ªç‚¹çš„3Dä½ç½®
                #     disp.append(disp_pred)
                #     # è®¡ç®—å½“å‰è·Ÿè¸ªç‚¹çš„è§†å·®
                #     pos_l.append(current_pos_l.clone())
                #     # ä¿å­˜å½“å‰è·Ÿè¸ªç‚¹çš„2Dä½ç½®
                #     pos_3d.append(pos)
                #
                #     # âœ… ç”¨äº‹ä»¶å¸§å¯è§†åŒ–ï¼ˆå¤šé€šé“å–å¹³å‡ï¼‰
                #     ev_img = ev_frame_l[0].detach().cpu()  # shape: [10, H, W]
                #     # å°†äº‹ä»¶å¸§è½¬æ¢ä¸ºå›¾åƒ
                #     if ev_img.ndim == 3 and ev_img.shape[0] == 10:
                #         ev_img_vis = ev_img.mean(dim=0).numpy() * 255           # shape: [H, W]
                #         img = np.stack([ev_img_vis]*3, axis=-1).astype(np.uint8)# shape: [H, W, 3]
                #     else:
                #         raise ValueError(f"Unsupported ev_frame_l shape: {ev_img.shape}")
                #     img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)                 # OpenCV BGRæ ¼å¼
                #
                #     # âœ… ç»˜åˆ¶è½¨è¿¹
                #     tracked_2d.append(current_pos_l[0].cpu().numpy())
                #     # ç»˜åˆ¶å½“å‰è·Ÿè¸ªç‚¹
                #     for p in tracked_2d:
                #         # ç»˜åˆ¶è½¨è¿¹
                #         img = draw_tracking(img, p)
                #     # ç»˜åˆ¶å½“å‰è·Ÿè¸ªç‚¹
                #     img = draw_tracking(img, current_pos_l[0].cpu().numpy(), color=(0, 0, 255))
                #     # ç»˜åˆ¶å‚è€ƒå›¾åƒ
                #     cv2.imshow(window_name, img)
                #     key = cv2.waitKey(30)
                #     if key == 27:  # ESC é€€å‡º
                #         break

                pos_3d = torch.stack(pos_3d)
                np.save(os.path.join(opFolder, 'pos_3d_pred.npy'), np.array(pos_3d.cpu()))
                np.save(os.path.join(opFolder, 'pos_3d_gt.npy'), np.array(gt['track_3d'][0].transpose(1, 0).cpu()))

                print(f'Test, Sequence: [{n}]/[{len(testDataset)}]')

        cv2.destroyAllWindows()